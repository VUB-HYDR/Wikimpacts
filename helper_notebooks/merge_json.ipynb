{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from dateparser.search import search_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shorouqza/Code/Wikimpacts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(x):\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    if isinstance(x, list):\n",
    "        return x[0]\n",
    "    elif isinstance(x, dict):\n",
    "        normalized_x = {}\n",
    "        for k,v in x.items():\n",
    "            normalized_x[k.strip().lower()] = str(v) \n",
    "        day, month, year, date, time = None, None, None, None, None\n",
    "        if \"year\" in normalized_x.keys(): \n",
    "            if \"year\" in normalized_x.keys():\n",
    "                year = normalized_x[\"year\"]\n",
    "            if \"month\" in normalized_x.keys():\n",
    "                month = normalized_x[\"month\"]\n",
    "               \n",
    "            if \"day\" in normalized_x.keys():\n",
    "                day = normalized_x[\"day\"]\n",
    "               \n",
    "        elif \"date\" in normalized_x.keys():\n",
    "            date = normalized_x[\"date\"]\n",
    "        elif \"time\" in normalized_x.keys():\n",
    "            time = normalized_x[\"time\"]\n",
    "        else:\n",
    "            for k in normalized_x.keys():\n",
    "                text = search_dates(normalized_x[k], settings={'STRICT_PARSING': False, 'DATE_ORDER': 'DMY'})\n",
    "                for x in text:\n",
    "                    if x:\n",
    "                        date_string =  x[0]\n",
    "                        date = date_string\n",
    "                        break   \n",
    "    \n",
    "    if year and month and day:\n",
    "        result = f\"{day}-{month}-{year}\"\n",
    "    elif year and month:\n",
    "        result = f\"{month}-{year}\"\n",
    "    elif year:\n",
    "        result = year\n",
    "    elif time: result = time\n",
    "    elif date: result = date # prefer date if present\n",
    "    else: \n",
    "        result = normalized_x\n",
    "        print(normalized_x)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "#model = \"mixtral-8x7B-dev\"\n",
    "model = \"mistral-7b\"\n",
    "\n",
    "#file_list_path = f\"Database/raw/nlp4climate/{model}-json\"\n",
    "# file_list_path = f\"Database/raw/nlp4climate/mistral_outputs/dev/Mistral-7B-Instruct-v0.2\"\n",
    "# file_list_path = \"Database/raw/nlp4climate/mistral_outputs/test/Mixtral-8x7B-Instruct-v0.1\"\n",
    "file_list_path = \"Database/raw/nlp4climate/mistral_outputs/test/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "file_list = os.listdir(file_list_path)\n",
    "file_list_relative = [f\"{file_list_path}/{i}\" for i in file_list if i and i.endswith(\".json\")]\n",
    "\n",
    "dfs = []\n",
    "for idx in range(len(file_list_relative)):\n",
    "    try:\n",
    "        json_file = json.load(open(file_list_relative[idx]))\n",
    "        country_col = None\n",
    "        if json_file:\n",
    "            columns = list(json_file.keys())\n",
    "            country_col = [i for i in columns if i.lower().strip().startswith(\"countr\") and not i.lower().strip().endswith(\"annotation\")]\n",
    "            #print(country_col)\n",
    "            if len(country_col) >= 1:\n",
    "                country_col = country_col[0]\n",
    "            else:\n",
    "                country_col = None\n",
    "        \n",
    "        if country_col:\n",
    "            # print(json_file[country_col])\n",
    "            try:\n",
    "                if len(json_file[country_col])>=1 and isinstance(json_file[country_col][0], str):\n",
    "                    json_file[\"Country_Merge\"] = json_file[country_col]\n",
    "                    #print(\"ready country col\")\n",
    "                elif len(json_file[country_col])>=1 and isinstance(json_file[country_col], list):\n",
    "                    if isinstance(json_file[country_col][0], dict) and (\"Country\" in json_file[country_col][0] or \"country\" in json_file[country_col][0]):\n",
    "                        #print(\"DICTIONARY\")\n",
    "                        json_file[\"Country_Merge\"] = [d[\"Country\"] for d in json_file[country_col]]\n",
    "                        #print(\"EXTRACTED\", json_file[\"Country_Merge\"])\n",
    "                    elif isinstance(json_file[country_col][0], dict) and (\"Country\" not in json_file[country_col][0] and \"country\" not in json_file[country_col][0]):\n",
    "                        json_file[\"Country_Merge\"] = list(json_file[country_col].keys())\n",
    "            except:\n",
    "                json_file[\"Country_Merge\"] = []\n",
    "\n",
    "        json_file[\"Event_Name\"] = file_list[idx].split(\".json\")[0]\n",
    "        if \"Start_Date\" in json_file.keys():\n",
    "            start_date = get_date(json_file[\"Start_Date\"])\n",
    "            json_file[\"Start_Date\"] = start_date\n",
    "        if \"End_Date\" in json_file.keys():\n",
    "            end_date = get_date(json_file[\"End_Date\"])\n",
    "            json_file[\"End_Date\"] = end_date\n",
    "\n",
    "        dfs.append(json_file)\n",
    "        print()\n",
    "    \n",
    "    except BaseException as err:\n",
    "        print(\"----\")\n",
    "        pprint.pprint(json_file)\n",
    "        print(type(json_file))\n",
    "        print(err)\n",
    "        # print(json_file)\n",
    "        # print(json_file[\"Start_Date\"])\n",
    "        # print(\"country_col\", country_col, json_file[country_col])\n",
    "        print()\n",
    "\n",
    "# df = pd.concat(dfs, ignore_index=True) # concatenate all the data frames in the list.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixtral = pd.DataFrame(dfs, columns=\n",
    "                             [\n",
    "                                 \"Event_ID\",\n",
    "                                \"Event_Name\",\n",
    "                                 \"Main_Event\",\n",
    "                                 \"Main_Event_Assessment_With_Annotation\",\n",
    "                                 \"Start_Date\",\n",
    "                                 \"End_Date\",\n",
    "                                 \"Time_with_Annotation\",\n",
    "                                 \"Country_Merge\",\n",
    "                                 \"Countries_Affected\",\n",
    "                                 \"Country_with_Annotation\",\n",
    "                                 \"Total_Summary_Death\",\n",
    "                                 \"Specific_Instance_Per_Country_Death\",\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_ids = pd.read_parquet(\"Database/output/nlp4climate/dev_set.parquet\", engine=\"pyarrow\")[[\"Event_Name\", \"Event_ID\"]]\n",
    "# event_ids = pd.read_json(\"Database/raw/nlp4climate/mistral-7b.json\")[[\"Event_Name\", \"Event_ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_ids = pd.read_json(\"Database/raw/nlp4climate/event_ids.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_ids[\"Event_Name\"] = event_ids[\"Event_Name\"].apply(lambda x: x.strip().replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixtral_ids = pd.merge(\n",
    "#    left=mixtral,\n",
    "#    right=event_ids,\n",
    "#    how=\"left\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixtral_ids.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mixtral_ids.shape\n",
    "mixtral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_ID</th>\n",
       "      <th>Event_Name</th>\n",
       "      <th>Main_Event</th>\n",
       "      <th>Main_Event_Assessment_With_Annotation</th>\n",
       "      <th>Start_Date</th>\n",
       "      <th>End_Date</th>\n",
       "      <th>Time_with_Annotation</th>\n",
       "      <th>Country_Merge</th>\n",
       "      <th>Countries_Affected</th>\n",
       "      <th>Country_with_Annotation</th>\n",
       "      <th>Total_Summary_Death</th>\n",
       "      <th>Specific_Instance_Per_Country_Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Event_ID, Event_Name, Main_Event, Main_Event_Assessment_With_Annotation, Start_Date, End_Date, Time_with_Annotation, Country_Merge, Countries_Affected, Country_with_Annotation, Total_Summary_Death, Specific_Instance_Per_Country_Death]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mixtral_ids[mixtral_ids[\"Event_ID\"].isna()]\n",
    "\n",
    "mixtral[mixtral[\"Event_ID\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixtral_ids.to_csv(f\"Database/raw/nlp4climate/mistral_outputs/dev/{model}.csv\")\n",
    "# mixtral_ids.to_json(f\"Database/raw/nlp4climate/mistral_outputs/dev/{model}.json\", orient=\"records\")\n",
    "mixtral.to_json(f\"Database/raw/nlp4climate/mistral_outputs/test/{model}.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixtral.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikimpacts-1uvlbl-K-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
